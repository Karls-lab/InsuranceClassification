{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in the data, we are only interested in headlines and category. \n",
    "One hot encode the categories\n",
    "\"\"\"\n",
    "if not os.path.exists(\"processedData.csv\"):\n",
    "\n",
    "    df = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "    # Downsample the data to 50000 samples\n",
    "    df = df.sample(n=100000, random_state=42)\n",
    "\n",
    "    target = ['Response']\n",
    "    boolean_vars = ['Gender', 'Driving_License', 'Previously_Insured', \n",
    "                    'Vehicle_Damage']\n",
    "    num_vars = ['Age', 'Annual_Premium', 'Vintage']\n",
    "    cat_vars = ['Region_Code', 'Vehicle_Age', 'Policy_Sales_Channel']\n",
    "\n",
    "    # Turn the boolean variables into 0 and 1\n",
    "    df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
    "    df['Vehicle_Damage'] = df['Vehicle_Damage'].map({'Yes': 1, 'No': 0})\n",
    "    df['Vehicle_Age'] = df['Vehicle_Age'].map({'< 1 Year': 0, '1-2 Year': 0.5, '> 2 Years': 1})\n",
    "    df[boolean_vars] = df[boolean_vars].astype('float16')\n",
    "\n",
    "    # Standardize The numerical variables\n",
    "    scaler = StandardScaler()\n",
    "    df[num_vars] = scaler.fit_transform(df[num_vars]).astype('float16')\n",
    "\n",
    "    # One hot encode the categorical variables\n",
    "    df = pd.get_dummies(df, columns=cat_vars, dtype='float16')\n",
    "\n",
    "    # Downscale Majority class 10 times to even out the classes \n",
    "    majorityClass = df.where(df['Response'] == 0).dropna()\n",
    "    minorityClass = df.where(df['Response'] == 1).dropna()\n",
    "    minorityCount = len(minorityClass)\n",
    "    downSampled = majorityClass.sample(n=minorityCount, random_state=42)\n",
    "    df = pd.concat([downSampled, minorityClass]) \n",
    "\n",
    "    # Shuffle the data\n",
    "    df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "    # display(df.columns)\n",
    "    # We are not going to use Region_Code or Policy_Sales_Channel\n",
    "    df = df[['Response', 'Age', 'Annual_Premium', 'Vintage',\n",
    "             'Gender', 'Vehicle_Damage', 'Previously_Insured', 'Driving_License']]\n",
    "    df['Response'] = df['Response'].astype('int8')\n",
    "\n",
    "    # Save the data\n",
    "    df.to_csv(\"processedData.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.initializers import HeNormal\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "from keras.layers import Dropout\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from keras.losses import BinaryCrossentropy \n",
    "from sklearn.metrics import recall_score\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "\n",
    "class B3D3AD_Classifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.classes_ = np.array([0, 1])  \n",
    "        self.model = Sequential([\n",
    "            self.DenseLayer(5000, activation='relu'),\n",
    "            self.DenseLayer(500, activation='relu'),\n",
    "            self.DropoutLayer(0.3),\n",
    "            self.DenseLayer(1, activation='sigmoid'),\n",
    "        ])\n",
    "        self.compile()\n",
    "\n",
    "    # Customer Dense layer\n",
    "    def DenseLayer(self, nodes, activation='relu'):\n",
    "        return Dense(\n",
    "            nodes, activation=activation, \n",
    "            kernel_initializer=HeNormal(), bias_initializer=HeNormal(),\n",
    "            kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)\n",
    "        )\n",
    "\n",
    "    # Custom dropout layer\n",
    "    def DropoutLayer(self, rate):\n",
    "        return Dropout(rate)\n",
    "\n",
    "    # Resets weights to HeNormal\n",
    "    def reset_weights(self):\n",
    "        initial_weights = self.model.get_weights()\n",
    "        self.model.set_weights(initial_weights)\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        # Predict probabilities\n",
    "        probabilities = self.model.predict(X)\n",
    "        # Convert probabilities to binary predictions using the threshold\n",
    "        predictions = (probabilities >= threshold).astype(int)\n",
    "        return predictions\n",
    "\n",
    "    # compile the model\n",
    "    def compile(self):\n",
    "        lr_scheduler = ExponentialDecay(initial_learning_rate=0.001, decay_steps=1, decay_rate=.1)\n",
    "        self.model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr_scheduler),\n",
    "                           loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
    "    # Calculate recall\n",
    "    def recall(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return recall_score(y, predictions)\n",
    "\n",
    "    # Run the model. Forward fit using a learning rate scheduler\n",
    "    def fit(self, X, training_labels, epochs=6, batch_size=32):\n",
    "        self.model.fit(X, training_labels, epochs=epochs, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7879901960784313\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train():\n",
    "    # Load the data\n",
    "    data = pd.read_csv(\"processedData.csv\")\n",
    "\n",
    "    # Split features and target columns\n",
    "    columns = data.columns.drop('Response')\n",
    "    X = data[columns]\n",
    "    y = data['Response'].astype(np.int8)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=True)\n",
    "\n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        'max_depth': [10, 15, 20],\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0, 1, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'eta': [0.01, 0.1, 0.2],\n",
    "        'lambda': [1, 2, 3],\n",
    "        'alpha': [0, 0.5, 1]\n",
    "    }\n",
    "\n",
    "    # Initialize the XGBoost classifier\n",
    "    xgb_clf = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        booster='dart',\n",
    "        eval_metric='logloss',\n",
    "        tree_method='hist',\n",
    "        scale_pos_weight=1,\n",
    "        nthread=8,\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search = GridSearchCV(estimator=xgb_clf, param_grid=param_grid, scoring='accuracy', cv=3, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters and model\n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    print(f'Best parameters found: {best_params}')\n",
    "\n",
    "    # Make predictions with the best model\n",
    "    y_pred_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
